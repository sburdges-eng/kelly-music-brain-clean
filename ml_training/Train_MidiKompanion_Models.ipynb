{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# miDiKompanion ML Model Training\n",
        "\n",
        "This notebook trains the 5-model pipeline for miDiKompanion:\n",
        "\n",
        "1. **EmotionRecognizer**: Audio features (128-dim) → Emotion embedding (64-dim)\n",
        "2. **MelodyTransformer**: Emotion embedding (64-dim) → MIDI probabilities (128-dim)\n",
        "3. **HarmonyPredictor**: Context (128-dim) → Chord probabilities (64-dim)\n",
        "4. **DynamicsEngine**: Intensity (32-dim) → Expression parameters (16-dim)\n",
        "5. **GroovePredictor**: Arousal (64-dim) → Groove parameters (32-dim)\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1. Set runtime to GPU: **Runtime → Change runtime type → GPU**\n",
        "2. Run all cells in order\n",
        "3. Download the trained models from the `models/onnx` folder\n",
        "\n",
        "Estimated training time: **8-14 hours** on Colab T4 GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q onnx onnxruntime\n",
        "!pip install -q numpy pandas scikit-learn tqdm\n",
        "\n",
        "print(\"Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_configs"
      },
      "outputs": [],
      "source": [
        "# Model configurations\n",
        "from dataclasses import dataclass\n",
        "from typing import List\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    name: str\n",
        "    input_size: int\n",
        "    output_size: int\n",
        "    hidden_sizes: List[int]\n",
        "    activation: str = 'relu'\n",
        "    dropout: float = 0.1\n",
        "    learning_rate: float = 0.001\n",
        "    batch_size: int = 32\n",
        "\n",
        "MODEL_CONFIGS = {\n",
        "    'emotion_recognizer': ModelConfig(\n",
        "        name='EmotionRecognizer',\n",
        "        input_size=128,\n",
        "        output_size=64,\n",
        "        hidden_sizes=[256, 128, 96],\n",
        "        dropout=0.2\n",
        "    ),\n",
        "    'melody_transformer': ModelConfig(\n",
        "        name='MelodyTransformer',\n",
        "        input_size=64,\n",
        "        output_size=128,\n",
        "        hidden_sizes=[128, 192, 160],\n",
        "        dropout=0.15\n",
        "    ),\n",
        "    'harmony_predictor': ModelConfig(\n",
        "        name='HarmonyPredictor',\n",
        "        input_size=128,\n",
        "        output_size=64,\n",
        "        hidden_sizes=[192, 128, 96],\n",
        "        dropout=0.1\n",
        "    ),\n",
        "    'dynamics_engine': ModelConfig(\n",
        "        name='DynamicsEngine',\n",
        "        input_size=32,\n",
        "        output_size=16,\n",
        "        hidden_sizes=[64, 48, 32],\n",
        "        dropout=0.1\n",
        "    ),\n",
        "    'groove_predictor': ModelConfig(\n",
        "        name='GroovePredictor',\n",
        "        input_size=64,\n",
        "        output_size=32,\n",
        "        hidden_sizes=[96, 64, 48],\n",
        "        dropout=0.1\n",
        "    )\n",
        "}\n",
        "\n",
        "print(\"Model configurations loaded!\")\n",
        "for key, config in MODEL_CONFIGS.items():\n",
        "    print(f\"  {config.name}: {config.input_size} → {config.output_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_arch"
      },
      "outputs": [],
      "source": [
        "# Define model architecture\n",
        "import torch.nn as nn\n",
        "\n",
        "class MiDiKompanionModel(nn.Module):\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        layers = []\n",
        "        prev_size = config.input_size\n",
        "\n",
        "        for hidden_size in config.hidden_sizes:\n",
        "            layers.append(nn.Linear(prev_size, hidden_size))\n",
        "            layers.append(nn.BatchNorm1d(hidden_size))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(config.dropout))\n",
        "            prev_size = hidden_size\n",
        "\n",
        "        layers.append(nn.Linear(prev_size, config.output_size))\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Test model creation\n",
        "test_model = MiDiKompanionModel(MODEL_CONFIGS['emotion_recognizer'])\n",
        "test_input = torch.randn(1, 128)\n",
        "test_output = test_model(test_input)\n",
        "print(f\"Test: {test_input.shape} → {test_output.shape}\")\n",
        "print(\"Model architecture OK!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dataset"
      },
      "outputs": [],
      "source": [
        "# Synthetic dataset generation\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SyntheticDataset(Dataset):\n",
        "    def __init__(self, config: ModelConfig, num_samples: int = 10000, seed: int = 42):\n",
        "        self.config = config\n",
        "        self.num_samples = num_samples\n",
        "\n",
        "        np.random.seed(seed)\n",
        "        self.inputs, self.targets = self._generate_data()\n",
        "\n",
        "    def _generate_data(self):\n",
        "        inputs = np.random.randn(self.num_samples, self.config.input_size).astype(np.float32)\n",
        "\n",
        "        if self.config.name == 'EmotionRecognizer':\n",
        "            targets = self._generate_emotion_targets(inputs)\n",
        "        elif self.config.name == 'MelodyTransformer':\n",
        "            targets = self._generate_melody_targets(inputs)\n",
        "        elif self.config.name == 'HarmonyPredictor':\n",
        "            targets = self._generate_harmony_targets(inputs)\n",
        "        elif self.config.name == 'DynamicsEngine':\n",
        "            targets = self._generate_dynamics_targets(inputs)\n",
        "        elif self.config.name == 'GroovePredictor':\n",
        "            targets = self._generate_groove_targets(inputs)\n",
        "        else:\n",
        "            targets = np.random.randn(self.num_samples, self.config.output_size).astype(np.float32)\n",
        "\n",
        "        return torch.FloatTensor(inputs), torch.FloatTensor(targets)\n",
        "\n",
        "    def _generate_emotion_targets(self, inputs):\n",
        "        targets = np.zeros((self.num_samples, self.config.output_size), dtype=np.float32)\n",
        "        targets[:, 0] = np.tanh(np.mean(inputs[:, :32], axis=1))\n",
        "        targets[:, 1] = np.tanh(np.mean(inputs[:, 32:64], axis=1))\n",
        "        targets[:, 2] = np.tanh(np.mean(inputs[:, 64:96], axis=1))\n",
        "        targets[:, 3] = np.abs(np.tanh(np.mean(inputs[:, 96:], axis=1)))\n",
        "        for i in range(4, self.config.output_size):\n",
        "            targets[:, i] = targets[:, i % 4] * np.sin(i * 0.5) + np.random.randn(self.num_samples) * 0.1\n",
        "        return np.clip(targets, -1, 1)\n",
        "\n",
        "    def _generate_melody_targets(self, inputs):\n",
        "        targets = np.zeros((self.num_samples, self.config.output_size), dtype=np.float32)\n",
        "        valence = inputs[:, 0]\n",
        "        arousal = inputs[:, 1]\n",
        "        base_note = 60 + (valence * 12)\n",
        "        range_spread = 6 + arousal * 12\n",
        "        for i in range(self.num_samples):\n",
        "            center = int(np.clip(base_note[i], 48, 84))\n",
        "            spread = int(np.clip(range_spread[i], 6, 24))\n",
        "            for note in range(self.config.output_size):\n",
        "                dist = abs(note - center)\n",
        "                targets[i, note] = np.exp(-(dist ** 2) / (2 * (spread ** 2)))\n",
        "        return targets / (targets.sum(axis=1, keepdims=True) + 1e-8)\n",
        "\n",
        "    def _generate_harmony_targets(self, inputs):\n",
        "        targets = np.zeros((self.num_samples, self.config.output_size), dtype=np.float32)\n",
        "        valence = inputs[:, 0]\n",
        "        for i in range(self.num_samples):\n",
        "            if valence[i] > 0:\n",
        "                targets[i, :32] = np.random.rand(32) * (0.5 + valence[i] * 0.5)\n",
        "                targets[i, 32:] = np.random.rand(32) * (0.5 - valence[i] * 0.3)\n",
        "            else:\n",
        "                targets[i, :32] = np.random.rand(32) * (0.5 + valence[i] * 0.3)\n",
        "                targets[i, 32:] = np.random.rand(32) * (0.5 - valence[i] * 0.5)\n",
        "        return targets / (targets.sum(axis=1, keepdims=True) + 1e-8)\n",
        "\n",
        "    def _generate_dynamics_targets(self, inputs):\n",
        "        targets = np.zeros((self.num_samples, self.config.output_size), dtype=np.float32)\n",
        "        intensity = np.mean(inputs, axis=1)\n",
        "        targets[:, 0] = 0.3 + intensity * 0.5\n",
        "        targets[:, 1] = 0.1 + np.abs(intensity) * 0.2\n",
        "        for i in range(2, self.config.output_size):\n",
        "            targets[:, i] = targets[:, i % 2] * (1 - i / 20)\n",
        "        return np.clip(targets, 0, 1)\n",
        "\n",
        "    def _generate_groove_targets(self, inputs):\n",
        "        targets = np.zeros((self.num_samples, self.config.output_size), dtype=np.float32)\n",
        "        arousal = np.mean(inputs[:, :32], axis=1)\n",
        "        targets[:, 0] = 0.5 + arousal * 0.3\n",
        "        targets[:, 1] = 0.2 + np.abs(arousal) * 0.3\n",
        "        for i in range(2, self.config.output_size):\n",
        "            targets[:, i] = np.random.rand(self.num_samples) * (0.3 + np.abs(arousal) * 0.4)\n",
        "        return np.clip(targets, 0, 1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx], self.targets[idx]\n",
        "\n",
        "print(\"Dataset class defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training"
      },
      "outputs": [],
      "source": [
        "# Training function\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "def train_model(model, config, train_loader, val_loader, epochs, device):\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    history = {'train_loss': [], 'val_loss': []}\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                val_losses.append(loss.item())\n",
        "\n",
        "        train_loss = np.mean(train_losses)\n",
        "        val_loss = np.mean(val_losses)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), f'{config.name.lower()}_best.pt')\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'  Epoch {epoch+1}/{epochs}: train={train_loss:.6f}, val={val_loss:.6f}')\n",
        "\n",
        "    model.load_state_dict(torch.load(f'{config.name.lower()}_best.pt'))\n",
        "    return history\n",
        "\n",
        "print(\"Training function defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_all"
      },
      "outputs": [],
      "source": [
        "# Train all models\n",
        "import os\n",
        "\n",
        "os.makedirs('models/onnx', exist_ok=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Training on: {device}\")\n",
        "\n",
        "EPOCHS = 100  # Increase for production training\n",
        "NUM_SAMPLES = 50000\n",
        "VAL_SPLIT = 0.1\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_key, config in MODEL_CONFIGS.items():\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training {config.name}...\")\n",
        "    print(f\"  Input: {config.input_size}, Output: {config.output_size}\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = SyntheticDataset(config, num_samples=NUM_SAMPLES)\n",
        "\n",
        "    val_size = int(len(dataset) * VAL_SPLIT)\n",
        "    train_size = len(dataset) - val_size\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size)\n",
        "\n",
        "    # Create and train model\n",
        "    model = MiDiKompanionModel(config)\n",
        "    start_time = time.time()\n",
        "\n",
        "    history = train_model(model, config, train_loader, val_loader, epochs=EPOCHS, device=device)\n",
        "\n",
        "    train_time = time.time() - start_time\n",
        "    print(f\"  Training time: {train_time:.1f}s\")\n",
        "\n",
        "    results[model_key] = {\n",
        "        'final_train_loss': history['train_loss'][-1],\n",
        "        'final_val_loss': history['val_loss'][-1],\n",
        "        'best_val_loss': min(history['val_loss']),\n",
        "        'train_time': train_time\n",
        "    }\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "export_onnx"
      },
      "outputs": [],
      "source": [
        "# Export to ONNX\n",
        "print(\"Exporting models to ONNX...\")\n",
        "\n",
        "for model_key, config in MODEL_CONFIGS.items():\n",
        "    model = MiDiKompanionModel(config)\n",
        "    model.load_state_dict(torch.load(f'{config.name.lower()}_best.pt', map_location='cpu'))\n",
        "    model.eval()\n",
        "\n",
        "    dummy_input = torch.randn(1, config.input_size)\n",
        "    onnx_path = f'models/onnx/{config.name.lower()}.onnx'\n",
        "\n",
        "    torch.onnx.export(\n",
        "        model,\n",
        "        dummy_input,\n",
        "        onnx_path,\n",
        "        input_names=['input'],\n",
        "        output_names=['output'],\n",
        "        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}},\n",
        "        opset_version=11,\n",
        "        do_constant_folding=True\n",
        "    )\n",
        "\n",
        "    size_kb = os.path.getsize(onnx_path) / 1024\n",
        "    print(f\"  {config.name}: {size_kb:.1f} KB\")\n",
        "\n",
        "# Total size\n",
        "total_size = sum(os.path.getsize(f'models/onnx/{c.name.lower()}.onnx') for c in MODEL_CONFIGS.values())\n",
        "print(f\"\\nTotal size: {total_size/1024:.1f} KB ({total_size/1024/1024:.2f} MB)\")\n",
        "print(\"✓ Export complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "verify"
      },
      "outputs": [],
      "source": [
        "# Verify models\n",
        "import onnx\n",
        "from onnxruntime import InferenceSession\n",
        "\n",
        "print(\"Verifying exported models...\")\n",
        "\n",
        "for model_key, config in MODEL_CONFIGS.items():\n",
        "    onnx_path = f'models/onnx/{config.name.lower()}.onnx'\n",
        "\n",
        "    # Load and check\n",
        "    onnx_model = onnx.load(onnx_path)\n",
        "    onnx.checker.check_model(onnx_model)\n",
        "\n",
        "    # Run inference\n",
        "    session = InferenceSession(onnx_path)\n",
        "    input_name = session.get_inputs()[0].name\n",
        "\n",
        "    test_input = np.random.randn(1, config.input_size).astype(np.float32)\n",
        "\n",
        "    # Benchmark\n",
        "    times = []\n",
        "    for _ in range(100):\n",
        "        start = time.time()\n",
        "        output = session.run(None, {input_name: test_input})\n",
        "        times.append((time.time() - start) * 1000)\n",
        "\n",
        "    avg_time = np.mean(times)\n",
        "    status = \"✓\" if avg_time < 10 else \"⚠\"\n",
        "\n",
        "    print(f\"  {status} {config.name}: {avg_time:.3f}ms (output shape: {output[0].shape})\")\n",
        "\n",
        "print(\"\\n✓ All models verified!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download"
      },
      "outputs": [],
      "source": [
        "# Download models\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "# Create zip file\n",
        "with zipfile.ZipFile('midikompanion_models.zip', 'w') as zipf:\n",
        "    for model_key, config in MODEL_CONFIGS.items():\n",
        "        onnx_path = f'models/onnx/{config.name.lower()}.onnx'\n",
        "        zipf.write(onnx_path, f'{config.name.lower()}.onnx')\n",
        "\n",
        "print(\"Models packaged in midikompanion_models.zip\")\n",
        "print(\"Downloading...\")\n",
        "\n",
        "files.download('midikompanion_models.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "## Results Summary\n",
        "\n",
        "After training, copy the models to your miDiKompanion installation:\n",
        "\n",
        "```bash\n",
        "unzip midikompanion_models.zip -d /path/to/miDiKompanion/models/onnx/\n",
        "```\n",
        "\n",
        "The models will be automatically loaded when you run miDiKompanion."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
